{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to look at how python can be used for concurrent programming. Even though Python is somewhat limited by GIL we have some basic level of cuncurrency support. \n",
    "\n",
    "Currency is supported in python via the following concepts\n",
    "1. `threads`\n",
    "2. `asyncio`\n",
    "3. `process`\n",
    "\n",
    "\n",
    "We'll look at an example were downloading items from the internet can be made faster with threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "'MX PH VN ET EG DE IR TR CD FR').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'http://flupy.org/data/flags'\n",
    "\n",
    "DEST_DIR = Path('download/')\n",
    "if not DEST_DIR.exists():\n",
    "    DEST_DIR.mkdir()\n",
    "    print('download dir created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flag(img, filename):\n",
    "    path = DEST_DIR/filename\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "        \n",
    "def get_flag(cc):\n",
    "    url = f\"{BASE_URL}/{cc.lower()}/{cc.lower()}.gif\"\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "def show(text):\n",
    "    print(text, end=' ')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def download_many(cc_list):\n",
    "    for cc in sorted(cc_list):\n",
    "        img = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(img, cc.lower()+'.gif')\n",
    "        \n",
    "    return len(cc_list)\n",
    "\n",
    "def main(download_many):\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 flags downloaded in 4.61s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading with concurrent.futures\n",
    "\n",
    "The main features of concurrent.futures are `ThreadPoolExecutor` and `ProcessPoolExecutor`. These abstract the inner workings of threads so we can work with a simple api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "def download_one(cc):\n",
    "    img = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(img, cc.lower()+'.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "        \n",
    "    return len(list(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR BD EG FR ET CD IN DE ID MX NGRU  IRCN  PHJPTR   US VN PK \n",
      "20 flags downloaded in 0.59s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see there is a major speedup simply by using concurrency.\n",
    "\n",
    "### Where are the Futures?\n",
    "\n",
    "Futures encapsulate pending operations so that they can be put in queues, their state of completion can be queried, and their results (or exceptions) can be retrieved when available.\n",
    "\n",
    "They are similar to `promise` object in javascript. \n",
    "\n",
    "Future instances are used in both concurrent.futures.Future and asyncio.Future. Both of the support `.done()`, `.add_done_callback()` and `.result()`. \n",
    "\n",
    "Several functions in both libraries return futures; others use them in their implementations but most of these are hidden from the user.\n",
    "\n",
    "\n",
    "To get a practical look into futures we'll rewrite the example above with futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_many(cc_list):\n",
    "    cc_list = cc_list[:5]\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        to_do = []\n",
    "        for cc in sorted(cc_list):\n",
    "            future = executor.submit(download_one, cc)\n",
    "            to_do.append(future)\n",
    "            msg = f'Scheduled for {cc}: {future}'\n",
    "            print(msg)\n",
    "            \n",
    "        results = []\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "            print(f'{future} result :{res}')\n",
    "            results.append(res)\n",
    "            \n",
    "        return len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR: <Future at 0x7f68251fced0 state=running>\n",
      "Scheduled for CN: <Future at 0x7f6824bb28d0 state=running>\n",
      "Scheduled for ID: <Future at 0x7f6824b0c390 state=running>\n",
      "Scheduled for IN: <Future at 0x7f682517ced0 state=pending>\n",
      "Scheduled for US: <Future at 0x7f682517c690 state=pending>\n",
      "CN BR <Future at 0x7f6824bb28d0 state=finished returned str> result :CN\n",
      "<Future at 0x7f68251fced0 state=finished returned str> result :BRID \n",
      "<Future at 0x7f6824b0c390 state=finished returned str> result :ID\n",
      "US <Future at 0x7f682517c690 state=finished returned str> result :US\n",
      "IN <Future at 0x7f682517ced0 state=finished returned str> result :IN\n",
      "\n",
      "5 flags downloaded in 0.58s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now stictly speaking we are still downloading over a single process due to the limitation from GIL. But we still get a good boost due to the fact that the is a I/O bound operation. \n",
    "\n",
    "For I/O bound operations the python interpreter frees the GIL and that mean other threads can execute. Even functions like `time.sleep()` releases the GIL.\n",
    "\n",
    "However if you want to leverage all the CPU cores you can use `ProcessPoolExecutor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_many(cc_list):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    \n",
    "    return len(list(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDBRCNCD    EGDEET   FR IDIN  JP IR MXNG  PK PH RU TRUS  VN \n",
      "20 flags downloaded in 1.85s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you noticed this is not as effective as `threads` mainly because in my system there are only 4 workers. For other CPU intensive tasks. For pure CPU intensive tasks however you should be using `pypy` instead which gives much better performance.\n",
    "\n",
    "## Experimenting with Executor.map\n",
    "simplest way to run serveral callables is using the map function. Here we'll look into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args):\n",
    "    print(strftime('[%H:%M:%S]'), end=' ')\n",
    "    print(*args)\n",
    "    \n",
    "def loiter(n):\n",
    "    msg = '{}loiter({}): doing nothing for {}s'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done.'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n*10\n",
    "\n",
    "def main():\n",
    "    display('Script starting')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3)\n",
    "    results = executor.map(loiter, range(10))\n",
    "    display('resutls', results)\n",
    "    display('Waiting for individual results')\n",
    "    for i, result in enumerate(results):\n",
    "        display('result {}: {}'.format(i, result))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:03] Script starting\n",
      "[13:26:03] loiter(0): doing nothing for 0s\n",
      "[13:26:03] loiter(0): done.\n",
      "[13:26:03][13:26:03] \tloiter(1): doing nothing for 1s\n",
      "[13:26:03] resutls <generator object Executor.map.<locals>.result_iterator at 0x7f9dac5e25d0>\n",
      "[13:26:03] Waiting for individual results\n",
      "[13:26:03] result 0: 0\n",
      "[13:26:03] \t\t\tloiter(3): doing nothing for 3s\n",
      " \t\tloiter(2): doing nothing for 2s\n",
      "[13:26:04] \tloiter(1): done.\n",
      "[13:26:04] \t\t\t\tloiter(4): doing nothing for 4s\n",
      "[13:26:04] result 1: 10\n",
      "[13:26:05] \t\tloiter(2): done.\n",
      "[13:26:05] \t\t\t\t\tloiter(5): doing nothing for 5s\n",
      "[13:26:05] result 2: 20\n",
      "[13:26:06] \t\t\tloiter(3): done.\n",
      "[13:26:06] \t\t\t\t\t\tloiter(6): doing nothing for 6s\n",
      "[13:26:06] result 3: 30\n",
      "[13:26:08] \t\t\t\tloiter(4): done.\n",
      "[13:26:08] \t\t\t\t\t\t\tloiter(7): doing nothing for 7s\n",
      "[13:26:08] result 4: 40\n",
      "[13:26:10] \t\t\t\t\tloiter(5): done.\n",
      "[13:26:10] [13:26:10] result 5: 50\n",
      "\t\t\t\t\t\t\t\tloiter(8): doing nothing for 8s\n",
      "[13:26:12] \t\t\t\t\t\tloiter(6): done.\n",
      "[13:26:12] \t\t\t\t\t\t\t\t\tloiter(9): doing nothing for 9s\n",
      "[13:26:12] result 6: 60\n",
      "[13:26:15] \t\t\t\t\t\t\tloiter(7): done.\n",
      "[13:26:15] result 7: 70\n",
      "[13:26:18] \t\t\t\t\t\t\t\tloiter(8): done.\n",
      "[13:26:18] result 8: 80\n",
      "[13:26:21] \t\t\t\t\t\t\t\t\tloiter(9): done.\n",
      "[13:26:21] result 9: 90\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Executor.map function is easy to use but it has a feature that may or may not be\n",
    "helpful, depending on your needs: it returns the results exactly in the same order as the\n",
    "calls are started: if the first call takes 10s to produce a result, and the others take 1s each,\n",
    "your code will block for 10s as it tries to retrieve the first result of the generator returned\n",
    "by map . After that, you’ll get the remaining results without blocking because they will\n",
    "be done. That’s OK when you must have all the results before proceeding, but often it’s\n",
    "preferable to get the results as they are ready, regardless of the order they were submitted.\n",
    "\n",
    "However if there is a situation were you need results as they are ready, regardless of the order they were submitted you would need a combination of `Executor.submit` method and `futures.as_completed` function.\n",
    "\n",
    "### Improved Script for flag download.\n",
    "\n",
    "Now lets try out an improved version of the download_flag script that has better error handling and a nice progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flags common\n",
    "from enum import Enum\n",
    "HTTPStatus = Enum('status', 'not_found')\n",
    "\n",
    "from collections import Namedtuple\n",
    "Results = Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_flag(base_url, cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    if resp.status != 200:\n",
    "        resp.raise_for_status()\n",
    "        \n",
    "    return resp.content\n",
    "\n",
    "def download_one(cc, base_url, verbose=False):\n",
    "    try: \n",
    "        image = get_flag(base_url, cc)\n",
    "    except requests.exceptions.HTTPError as exc:\n",
    "        res = exc.response\n",
    "        if res.status_code == 404:\n",
    "            status = HTTPStatus.not_found\n",
    "            msg = 'not found'\n",
    "        else:\n",
    "            raise\n",
    "    else:\n",
    "        save_flag(image, cc.lower()+'.gif')\n",
    "        status = HTTPStatus.ok\n",
    "        msg = 'OK'\n",
    "    \n",
    "    if verbose:\n",
    "        print(cc, msg)\n",
    "        \n",
    "    return Result(status, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'status'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTTPStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
