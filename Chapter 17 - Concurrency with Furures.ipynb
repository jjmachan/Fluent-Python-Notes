{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to look at how python can be used for concurrent programming. Even though Python is somewhat limited by GIL we have some basic level of cuncurrency support. \n",
    "\n",
    "Currency is supported in python via the following concepts\n",
    "1. `threads`\n",
    "2. `asyncio`\n",
    "3. `process`\n",
    "\n",
    "\n",
    "We'll look at an example were downloading items from the internet can be made faster with threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "'MX PH VN ET EG DE IR TR CD FR').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'http://flupy.org/data/flags'\n",
    "\n",
    "DEST_DIR = Path('download/')\n",
    "if not DEST_DIR.exists():\n",
    "    DEST_DIR.mkdir()\n",
    "    print('download dir created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flag(img, filename):\n",
    "    path = DEST_DIR/filename\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "        \n",
    "def get_flag(cc):\n",
    "    url = f\"{BASE_URL}/{cc.lower()}/{cc.lower()}.gif\"\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "def show(text):\n",
    "    print(text, end=' ')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def download_many(cc_list):\n",
    "    for cc in sorted(cc_list):\n",
    "        img = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(img, cc.lower()+'.gif')\n",
    "        \n",
    "    return len(cc_list)\n",
    "\n",
    "def main(download_many):\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 flags downloaded in 4.61s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading with concurrent.futures\n",
    "\n",
    "The main features of concurrent.futures are `ThreadPoolExecutor` and `ProcessPoolExecutor`. These abstract the inner workings of threads so we can work with a simple api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "def download_one(cc):\n",
    "    img = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(img, cc.lower()+'.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "        \n",
    "    return len(list(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR BD EG FR ET CD IN DE ID MX NGRU  IRCN  PHJPTR   US VN PK \n",
      "20 flags downloaded in 0.59s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see there is a major speedup simply by using concurrency.\n",
    "\n",
    "### Where are the Futures?\n",
    "\n",
    "Futures encapsulate pending operations so that they can be put in queues, their state of completion can be queried, and their results (or exceptions) can be retrieved when available.\n",
    "\n",
    "They are similar to `promise` object in javascript. \n",
    "\n",
    "Future instances are used in both concurrent.futures.Future and asyncio.Future. Both of the support `.done()`, `.add_done_callback()` and `.result()`. \n",
    "\n",
    "Several functions in both libraries return futures; others use them in their implementations but most of these are hidden from the user.\n",
    "\n",
    "\n",
    "To get a practical look into futures we'll rewrite the example above with futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_many(cc_list):\n",
    "    cc_list = cc_list[:5]\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        to_do = []\n",
    "        for cc in sorted(cc_list):\n",
    "            future = executor.submit(download_one, cc)\n",
    "            to_do.append(future)\n",
    "            msg = f'Scheduled for {cc}: {future}'\n",
    "            print(msg)\n",
    "            \n",
    "        results = []\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "            print(f'{future} result :{res}')\n",
    "            results.append(res)\n",
    "            \n",
    "        return len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR: <Future at 0x7f68251fced0 state=running>\n",
      "Scheduled for CN: <Future at 0x7f6824bb28d0 state=running>\n",
      "Scheduled for ID: <Future at 0x7f6824b0c390 state=running>\n",
      "Scheduled for IN: <Future at 0x7f682517ced0 state=pending>\n",
      "Scheduled for US: <Future at 0x7f682517c690 state=pending>\n",
      "CN BR <Future at 0x7f6824bb28d0 state=finished returned str> result :CN\n",
      "<Future at 0x7f68251fced0 state=finished returned str> result :BRID \n",
      "<Future at 0x7f6824b0c390 state=finished returned str> result :ID\n",
      "US <Future at 0x7f682517c690 state=finished returned str> result :US\n",
      "IN <Future at 0x7f682517ced0 state=finished returned str> result :IN\n",
      "\n",
      "5 flags downloaded in 0.58s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now stictly speaking we are still downloading over a single process due to the limitation from GIL. But we still get a good boost due to the fact that the is a I/O bound operation. \n",
    "\n",
    "For I/O bound operations the python interpreter frees the GIL and that mean other threads can execute. Even functions like `time.sleep()` releases the GIL.\n",
    "\n",
    "However if you want to leverage all the CPU cores you can use `ProcessPoolExecutor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_many(cc_list):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    \n",
    "    return len(list(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDBRCNCD    EGDEET   FR IDIN  JP IR MXNG  PK PH RU TRUS  VN \n",
      "20 flags downloaded in 1.85s\n"
     ]
    }
   ],
   "source": [
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you noticed this is not as effective as `threads` mainly because in my system there are only 4 workers. For other CPU intensive tasks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
